<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Hexo</title>
  
  
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2025-08-24T20:20:50.000Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>John Doe</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>YOLOv3 model.py代码的简单分析注解</title>
    <link href="http://example.com/wiki/Yolo%E5%AD%A6%E4%B9%A0/YOLOv3/"/>
    <id>http://example.com/wiki/Yolo%E5%AD%A6%E4%B9%A0/YOLOv3/</id>
    <published>2025-08-20T13:01:27.000Z</published>
    <updated>2025-08-24T20:20:50.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="YOLOv3-model-py代码的简单分析注解"><a href="#YOLOv3-model-py代码的简单分析注解" class="headerlink" title="YOLOv3 model.py代码的简单分析注解"></a>YOLOv3 model.py代码的简单分析注解</h1><h2 id="准备"><a href="#准备" class="headerlink" title="&gt; 准备"></a>&gt; 准备</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> functools <span class="keyword">import</span> wraps</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> keras <span class="keyword">import</span> backend <span class="keyword">as</span> K</span><br><span class="line"><span class="keyword">from</span> keras.layers <span class="keyword">import</span> Conv2D, Add, ZeroPadding2D, UpSampling2D, Concatenate, MaxPooling2D</span><br><span class="line"><span class="keyword">from</span> keras.layers.advanced_activations <span class="keyword">import</span> LeakyReLU</span><br><span class="line"><span class="keyword">from</span> keras.layers.normalization <span class="keyword">import</span> BatchNormalization</span><br><span class="line"><span class="keyword">from</span> keras.models <span class="keyword">import</span> Model</span><br><span class="line"><span class="keyword">from</span> keras.regularizers <span class="keyword">import</span> l2</span><br><span class="line"><span class="keyword">from</span> yolo3.utils <span class="keyword">import</span> compose</span><br></pre></td></tr></table></figure><h2 id="YOLO网络"><a href="#YOLO网络" class="headerlink" title="&gt; YOLO网络"></a>&gt; YOLO网络</h2><h4 id="首先要通过特征提取网络对输入的输入图像提取特征，得到不同尺寸的特征图"><a href="#首先要通过特征提取网络对输入的输入图像提取特征，得到不同尺寸的特征图" class="headerlink" title="首先要通过特征提取网络对输入的输入图像提取特征，得到不同尺寸的特征图"></a>首先要通过特征提取网络对输入的输入图像提取特征，得到不同尺寸的特征图</h4><pre><code>### 代码</code></pre><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@wraps(<span class="params">Conv2D</span>)</span><span class="comment">#@wraps在此处的作用是为了使DarknetConv2D.__name__和DarknetConv2D.__doc__与Conv2D__name__和Conv2D.__doc__相同。</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">DarknetConv2D</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Wrapper to set Darknet parameters for Convolution2D.&quot;&quot;&quot;</span></span><br><span class="line">    darknet_conv_kwargs = &#123;<span class="string">&#x27;kernel_regularizer&#x27;</span>: l2(<span class="number">5e-4</span>)&#125;</span><br><span class="line">    darknet_conv_kwargs[<span class="string">&#x27;padding&#x27;</span>] = <span class="string">&#x27;valid&#x27;</span> <span class="keyword">if</span> kwargs.get(<span class="string">&#x27;strides&#x27;</span>)==(<span class="number">2</span>,<span class="number">2</span>) <span class="keyword">else</span> <span class="string">&#x27;same&#x27;</span></span><br><span class="line">    darknet_conv_kwargs.update(kwargs)</span><br><span class="line">    <span class="keyword">return</span> Conv2D(*args, **darknet_conv_kwargs)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">DarknetConv2D_BN_Leaky</span>(<span class="params">*args, **kwargs</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Darknet Convolution2D followed by BatchNormalization and LeakyReLU.&quot;&quot;&quot;</span></span><br><span class="line">    no_bias_kwargs = &#123;<span class="string">&#x27;use_bias&#x27;</span>: <span class="literal">False</span>&#125;</span><br><span class="line">    no_bias_kwargs.update(kwargs)</span><br><span class="line">    <span class="keyword">return</span> compose(</span><br><span class="line">        DarknetConv2D(*args, **no_bias_kwargs),</span><br><span class="line">        BatchNormalization(),</span><br><span class="line">        LeakyReLU(alpha=<span class="number">0.1</span>))</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">resblock_body</span>(<span class="params">x, num_filters, num_blocks</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;A series of resblocks starting with a downsampling Convolution2D&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># Darknet uses left and top padding instead of &#x27;same&#x27; mode</span></span><br><span class="line">    x = ZeroPadding2D(((<span class="number">1</span>,<span class="number">0</span>),(<span class="number">1</span>,<span class="number">0</span>)))(x)<span class="comment">#((top_pad,bottom_pad),(left_pad,right_pad))   这里的ZeroPadding2D是为紧跟着的DBL服务的，使其尺寸正好缩小为原来的一半</span></span><br><span class="line">    x = DarknetConv2D_BN_Leaky(num_filters, (<span class="number">3</span>,<span class="number">3</span>), strides=(<span class="number">2</span>,<span class="number">2</span>))(x)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(num_blocks):</span><br><span class="line">        y = compose(</span><br><span class="line">                DarknetConv2D_BN_Leaky(num_filters//<span class="number">2</span>, (<span class="number">1</span>,<span class="number">1</span>)),</span><br><span class="line">                DarknetConv2D_BN_Leaky(num_filters, (<span class="number">3</span>,<span class="number">3</span>)))(x)</span><br><span class="line">        x = Add()([x,y])</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">darknet_body</span>(<span class="params">x</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Darknent body having 52 Convolution2D layers&#x27;&#x27;&#x27;</span></span><br><span class="line">    x = DarknetConv2D_BN_Leaky(<span class="number">32</span>, (<span class="number">3</span>,<span class="number">3</span>))(x)</span><br><span class="line">    x = resblock_body(x, <span class="number">64</span>, <span class="number">1</span>)</span><br><span class="line">    x = resblock_body(x, <span class="number">128</span>, <span class="number">2</span>)</span><br><span class="line">    x = resblock_body(x, <span class="number">256</span>, <span class="number">8</span>)</span><br><span class="line">    x = resblock_body(x, <span class="number">512</span>, <span class="number">8</span>)</span><br><span class="line">    x = resblock_body(x, <span class="number">1024</span>, <span class="number">4</span>)</span><br><span class="line">    <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">make_last_layers</span>(<span class="params">x, num_filters, out_filters</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;6 Conv2D_BN_Leaky layers followed by a Conv2D_linear layer&#x27;&#x27;&#x27;</span></span><br><span class="line">    x = compose(</span><br><span class="line">            DarknetConv2D_BN_Leaky(num_filters, (<span class="number">1</span>,<span class="number">1</span>)),</span><br><span class="line">            DarknetConv2D_BN_Leaky(num_filters*<span class="number">2</span>, (<span class="number">3</span>,<span class="number">3</span>)),</span><br><span class="line">            DarknetConv2D_BN_Leaky(num_filters, (<span class="number">1</span>,<span class="number">1</span>)),</span><br><span class="line">            DarknetConv2D_BN_Leaky(num_filters*<span class="number">2</span>, (<span class="number">3</span>,<span class="number">3</span>)),</span><br><span class="line">            DarknetConv2D_BN_Leaky(num_filters, (<span class="number">1</span>,<span class="number">1</span>)))(x)</span><br><span class="line">    y = compose(</span><br><span class="line">            DarknetConv2D_BN_Leaky(num_filters*<span class="number">2</span>, (<span class="number">3</span>,<span class="number">3</span>)),</span><br><span class="line">            DarknetConv2D(out_filters, (<span class="number">1</span>,<span class="number">1</span>)))(x)</span><br><span class="line">    <span class="keyword">return</span> x, y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">yolo_body</span>(<span class="params">inputs, num_anchors, num_classes</span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Create YOLO_V3 model CNN body in Keras.&quot;&quot;&quot;</span></span><br><span class="line">    darknet = Model(inputs, darknet_body(inputs))</span><br><span class="line">    <span class="comment">#第一个特征层y1=(batch_size,13,13,3,85)</span></span><br><span class="line">    x, y1 = make_last_layers(darknet.output, <span class="number">512</span>, num_anchors*(num_classes+<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">    x = compose(</span><br><span class="line">            DarknetConv2D_BN_Leaky(<span class="number">256</span>, (<span class="number">1</span>,<span class="number">1</span>)),</span><br><span class="line">            UpSampling2D(<span class="number">2</span>))(x)</span><br><span class="line">    x = Concatenate()([x,darknet.layers[<span class="number">152</span>].output])<span class="comment">#darknet.layers[152].output]#这里的[152]中的数字为对应层数</span></span><br><span class="line">    <span class="comment">#第二个特征层y2=(batch_size,26,26,3,85)</span></span><br><span class="line">    x, y2 = make_last_layers(x, <span class="number">256</span>, num_anchors*(num_classes+<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">    x = compose(</span><br><span class="line">            DarknetConv2D_BN_Leaky(<span class="number">128</span>, (<span class="number">1</span>,<span class="number">1</span>)),</span><br><span class="line">            UpSampling2D(<span class="number">2</span>))(x)</span><br><span class="line">    x = Concatenate()([x,darknet.layers[<span class="number">92</span>].output])</span><br><span class="line">    <span class="comment">#第三个特征层y3=(batch_size,52,52,3,85)</span></span><br><span class="line">    x, y3 = make_last_layers(x, <span class="number">128</span>, num_anchors*(num_classes+<span class="number">5</span>))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Model(inputs, [y1,y2,y3])</span><br></pre></td></tr></table></figure><h3 id="流程图"><a href="#流程图" class="headerlink" title="流程图"></a>流程图</h3><p><a href="https://imgtu.com/i/o3tSts"><img src="https://z3.ax1x.com/2021/11/30/o3tSts.png" alt="o3tSts.png"></a></p><h3 id="整个yolov3网络共252层"><a href="#整个yolov3网络共252层" class="headerlink" title="整个yolov3网络共252层"></a>整个yolov3网络共252层</h3><h2 id="tiny-yolo-body"><a href="#tiny-yolo-body" class="headerlink" title="&gt; tiny_yolo_body"></a>&gt; tiny_yolo_body</h2><h4 id="轻量版的YOLO-有速度快，占内存少等的优点，视情况选择使用。"><a href="#轻量版的YOLO-有速度快，占内存少等的优点，视情况选择使用。" class="headerlink" title="轻量版的YOLO,有速度快，占内存少等的优点，视情况选择使用。"></a>轻量版的YOLO,有速度快，占内存少等的优点，视情况选择使用。</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">tiny_yolo_body</span>(<span class="params">inputs, num_anchors, num_classes</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Create Tiny YOLO_v3 model CNN body in keras.&#x27;&#x27;&#x27;</span></span><br><span class="line">    x1 = compose(</span><br><span class="line">            DarknetConv2D_BN_Leaky(<span class="number">16</span>, (<span class="number">3</span>,<span class="number">3</span>)),</span><br><span class="line">            MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>), padding=<span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">            DarknetConv2D_BN_Leaky(<span class="number">32</span>, (<span class="number">3</span>,<span class="number">3</span>)),</span><br><span class="line">            MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>), padding=<span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">            DarknetConv2D_BN_Leaky(<span class="number">64</span>, (<span class="number">3</span>,<span class="number">3</span>)),</span><br><span class="line">            MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>), padding=<span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">            DarknetConv2D_BN_Leaky(<span class="number">128</span>, (<span class="number">3</span>,<span class="number">3</span>)),</span><br><span class="line">            MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>), padding=<span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">            DarknetConv2D_BN_Leaky(<span class="number">256</span>, (<span class="number">3</span>,<span class="number">3</span>)))(inputs)</span><br><span class="line">    x2 = compose(</span><br><span class="line">            MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">2</span>,<span class="number">2</span>), padding=<span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">            DarknetConv2D_BN_Leaky(<span class="number">512</span>, (<span class="number">3</span>,<span class="number">3</span>)),</span><br><span class="line">            MaxPooling2D(pool_size=(<span class="number">2</span>,<span class="number">2</span>), strides=(<span class="number">1</span>,<span class="number">1</span>), padding=<span class="string">&#x27;same&#x27;</span>),</span><br><span class="line">            DarknetConv2D_BN_Leaky(<span class="number">1024</span>, (<span class="number">3</span>,<span class="number">3</span>)),</span><br><span class="line">            DarknetConv2D_BN_Leaky(<span class="number">256</span>, (<span class="number">1</span>,<span class="number">1</span>)))(x1)</span><br><span class="line">    y1 = compose(</span><br><span class="line">            DarknetConv2D_BN_Leaky(<span class="number">512</span>, (<span class="number">3</span>,<span class="number">3</span>)),</span><br><span class="line">            DarknetConv2D(num_anchors*(num_classes+<span class="number">5</span>), (<span class="number">1</span>,<span class="number">1</span>)))(x2)</span><br><span class="line"></span><br><span class="line">    x2 = compose(</span><br><span class="line">            DarknetConv2D_BN_Leaky(<span class="number">128</span>, (<span class="number">1</span>,<span class="number">1</span>)),</span><br><span class="line">            UpSampling2D(<span class="number">2</span>))(x2)</span><br><span class="line">    y2 = compose(</span><br><span class="line">            Concatenate(),</span><br><span class="line">            DarknetConv2D_BN_Leaky(<span class="number">256</span>, (<span class="number">3</span>,<span class="number">3</span>)),</span><br><span class="line">            DarknetConv2D(num_anchors*(num_classes+<span class="number">5</span>), (<span class="number">1</span>,<span class="number">1</span>)))([x2,x1])</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> Model(inputs, [y1,y2])</span><br></pre></td></tr></table></figure><h2 id="预测框的获得"><a href="#预测框的获得" class="headerlink" title="&gt; 预测框的获得"></a>&gt; 预测框的获得</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#将预测值的每个特征层调成真实值</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">yolo_head</span>(<span class="params">feats, anchors, num_classes, input_shape, calc_loss=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Convert final layer features to bounding box parameters.&quot;&quot;&quot;</span></span><br><span class="line">    num_anchors = <span class="built_in">len</span>(anchors)<span class="comment">#num_anchors=3</span></span><br><span class="line">    <span class="comment"># Reshape to batch, height, width, num_anchors, box_params.</span></span><br><span class="line">    anchors_tensor = K.reshape(K.constant(anchors), [<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, num_anchors, <span class="number">2</span>])</span><br><span class="line">    grid_shape = K.shape(feats)[<span class="number">1</span>:<span class="number">3</span>] <span class="comment"># height, width</span></span><br><span class="line">    grid_y = K.tile(K.reshape(K.arange(<span class="number">0</span>, stop=grid_shape[<span class="number">0</span>]), [-<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]),</span><br><span class="line">        [<span class="number">1</span>, grid_shape[<span class="number">1</span>], <span class="number">1</span>, <span class="number">1</span>])<span class="comment">#将x在各个维度上重复n次，x为张量，n为与x维度数目相同的列表</span></span><br><span class="line">    grid_x = K.tile(K.reshape(K.arange(<span class="number">0</span>, stop=grid_shape[<span class="number">1</span>]), [<span class="number">1</span>, -<span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>]),</span><br><span class="line">        [grid_shape[<span class="number">0</span>], <span class="number">1</span>, <span class="number">1</span>, <span class="number">1</span>])</span><br><span class="line">    grid = K.concatenate([grid_x, grid_y])<span class="comment">#从倒数第1个维度进行拼接,可视为得到每个单元格左上角的坐标</span></span><br><span class="line">    grid = K.cast(grid, K.dtype(feats))</span><br><span class="line"></span><br><span class="line">    feats = K.reshape(</span><br><span class="line">        feats, [-<span class="number">1</span>, grid_shape[<span class="number">0</span>], grid_shape[<span class="number">1</span>], num_anchors, num_classes + <span class="number">5</span>])<span class="comment">#(batch_size,13,13,3,85)</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Adjust preditions to each spatial grid point and anchor size.</span></span><br><span class="line">    <span class="comment">#box_xy对应框的中心点，box_wh对应框的宽和高</span></span><br><span class="line">    box_xy = (K.sigmoid(feats[..., :<span class="number">2</span>]) + grid) / K.cast(grid_shape[::-<span class="number">1</span>], K.dtype(feats))<span class="comment">#grid 为偏移 ，将x,y相对于featuremap尺寸进行了归一化</span></span><br><span class="line">    box_wh = K.exp(feats[..., <span class="number">2</span>:<span class="number">4</span>]) * anchors_tensor / K.cast(input_shape[::-<span class="number">1</span>], K.dtype(feats))<span class="comment">#exp() 方法返回x的指数,ex。</span></span><br><span class="line">    box_confidence = K.sigmoid(feats[..., <span class="number">4</span>:<span class="number">5</span>])<span class="comment">#置信率</span></span><br><span class="line">    box_class_probs = K.sigmoid(feats[..., <span class="number">5</span>:])<span class="comment">#80个类别</span></span><br><span class="line">    <span class="comment">#在计算loss的时候返回以下参数</span></span><br><span class="line">    <span class="keyword">if</span> calc_loss == <span class="literal">True</span>:</span><br><span class="line">        <span class="keyword">return</span> grid, feats, box_xy, box_wh</span><br><span class="line">    <span class="keyword">return</span> box_xy, box_wh, box_confidence, box_class_probs</span><br><span class="line"></span><br><span class="line"><span class="comment">#对box进行调整，使其符合真实图片的样子</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">yolo_correct_boxes</span>(<span class="params">box_xy, box_wh, input_shape, image_shape</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Get corrected boxes&#x27;&#x27;&#x27;</span></span><br><span class="line">    box_yx = box_xy[..., ::-<span class="number">1</span>]</span><br><span class="line">    box_hw = box_wh[..., ::-<span class="number">1</span>]</span><br><span class="line">    input_shape = K.cast(input_shape, K.dtype(box_yx))</span><br><span class="line">    image_shape = K.cast(image_shape, K.dtype(box_yx))</span><br><span class="line">    <span class="comment">#这里K.min取较小值，便于后续步骤调整适应image的尺寸，new是image等比缩小得来</span></span><br><span class="line">    new_shape = K.<span class="built_in">round</span>(image_shape * K.<span class="built_in">min</span>(input_shape/image_shape))<span class="comment">#K.round()底层即为tf.round(),Bankers Rounding——四舍六入五取偶,如4.5——&gt;4;3.5——&gt;4</span></span><br><span class="line">    offset = (input_shape-new_shape)/<span class="number">2.</span>/input_shape</span><br><span class="line">    scale = input_shape/new_shape</span><br><span class="line">    box_yx = (box_yx - offset) * scale</span><br><span class="line">    box_hw *= scale</span><br><span class="line"></span><br><span class="line">    box_mins = box_yx - (box_hw / <span class="number">2.</span>)</span><br><span class="line">    box_maxes = box_yx + (box_hw / <span class="number">2.</span>)</span><br><span class="line">    boxes =  K.concatenate([</span><br><span class="line">        box_mins[..., <span class="number">0</span>:<span class="number">1</span>],  <span class="comment"># y_min</span></span><br><span class="line">        box_mins[..., <span class="number">1</span>:<span class="number">2</span>],  <span class="comment"># x_min</span></span><br><span class="line">        box_maxes[..., <span class="number">0</span>:<span class="number">1</span>],  <span class="comment"># y_max</span></span><br><span class="line">        box_maxes[..., <span class="number">1</span>:<span class="number">2</span>]  <span class="comment"># x_max</span></span><br><span class="line">    ])<span class="comment">#（x_min,y_min),（x_max,y_max)分别为左上，右下点的坐标</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Scale boxes back to original image shape.</span></span><br><span class="line">    boxes *= K.concatenate([image_shape, image_shape])</span><br><span class="line">    <span class="keyword">return</span> boxes</span><br><span class="line"></span><br><span class="line"><span class="comment">#获取每个box和它的得分</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">yolo_boxes_and_scores</span>(<span class="params">feats, anchors, num_classes, input_shape, image_shape</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Process Conv layer output&#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="comment"># -1,13,13,3,2;-1,13,13,3,2;-1,13,13,3,1;-1,13,13,3,80;</span></span><br><span class="line"></span><br><span class="line">    box_xy, box_wh, box_confidence, box_class_probs = yolo_head(feats,</span><br><span class="line">        anchors, num_classes, input_shape)</span><br><span class="line">    <span class="comment">#将box_xy,box_wh调节成y_min,y_max,x_min,x_max</span></span><br><span class="line">    boxes = yolo_correct_boxes(box_xy, box_wh, input_shape, image_shape)</span><br><span class="line">    boxes = K.reshape(boxes, [-<span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line">    box_scores = box_confidence * box_class_probs</span><br><span class="line">    box_scores = K.reshape(box_scores, [-<span class="number">1</span>, num_classes])</span><br><span class="line">    <span class="keyword">return</span> boxes, box_scores</span><br></pre></td></tr></table></figure><h3 id="求得bx-by-bw-bh的公式"><a href="#求得bx-by-bw-bh的公式" class="headerlink" title="求得bx,by,bw,bh的公式"></a>求得bx,by,bw,bh的公式</h3><p><a href="https://imgtu.com/i/o3Yj0g"><img src="https://z3.ax1x.com/2021/11/30/o3Yj0g.png" alt="o3Yj0g.png"></a></p><h2 id="寻找最佳的anchor-box"><a href="#寻找最佳的anchor-box" class="headerlink" title="&gt; 寻找最佳的anchor box"></a>&gt; 寻找最佳的anchor box</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">preprocess_true_boxes</span>(<span class="params">true_boxes, input_shape, anchors, num_classes</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Preprocess true boxes to training input format</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    true_boxes: array, shape=(m, T, 5)</span></span><br><span class="line"><span class="string">        Absolute x_min, y_min, x_max, y_max, class_id relative to input_shape.</span></span><br><span class="line"><span class="string">    input_shape: array-like, hw, multiples of 32</span></span><br><span class="line"><span class="string">    anchors: array, shape=(N, 2), wh</span></span><br><span class="line"><span class="string">    num_classes: integer</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    y_true: list of array, shape like yolo_outputs, xywh are reletive value</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    <span class="keyword">assert</span> (true_boxes[..., <span class="number">4</span>]&lt;num_classes).<span class="built_in">all</span>(), <span class="string">&#x27;class id must be less than num_classes&#x27;</span></span><br><span class="line">    <span class="comment">#assert（断言）用于判断一个表达式，在表达式条件为 false 的时候触发异常。</span></span><br><span class="line">    <span class="comment">#.all（）测试沿给定轴的所有数组元素是否都计算为True。元素除了是 0、空、None、False 外都算 True</span></span><br><span class="line">    num_layers = <span class="built_in">len</span>(anchors)//<span class="number">3</span> <span class="comment"># default setting</span></span><br><span class="line">    <span class="comment"># 先验框</span></span><br><span class="line">    <span class="comment"># 678为116，90；156，198；373，326</span></span><br><span class="line">    <span class="comment"># 345为30，61；62，45；59，119</span></span><br><span class="line">    <span class="comment"># 012为10，13；16，30；33，23</span></span><br><span class="line"></span><br><span class="line">    anchor_mask = [[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>], [<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>], [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]] <span class="keyword">if</span> num_layers==<span class="number">3</span> <span class="keyword">else</span> [[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>], [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]]</span><br><span class="line"></span><br><span class="line">    true_boxes = np.array(true_boxes, dtype=<span class="string">&#x27;float32&#x27;</span>)</span><br><span class="line">    input_shape = np.array(input_shape, dtype=<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line">    <span class="comment">#将边框的两点坐标形式，转化成训练的中心加边长形式，并进行归一化</span></span><br><span class="line">    boxes_xy = (true_boxes[..., <span class="number">0</span>:<span class="number">2</span>] + true_boxes[..., <span class="number">2</span>:<span class="number">4</span>]) // <span class="number">2</span></span><br><span class="line">    boxes_wh = true_boxes[..., <span class="number">2</span>:<span class="number">4</span>] - true_boxes[..., <span class="number">0</span>:<span class="number">2</span>]</span><br><span class="line">    true_boxes[..., <span class="number">0</span>:<span class="number">2</span>] = boxes_xy/input_shape[::-<span class="number">1</span>]</span><br><span class="line">    true_boxes[..., <span class="number">2</span>:<span class="number">4</span>] = boxes_wh/input_shape[::-<span class="number">1</span>]</span><br><span class="line"></span><br><span class="line">    m = true_boxes.shape[<span class="number">0</span>]<span class="comment">#m张图片</span></span><br><span class="line">    grid_shapes = [input_shape//&#123;<span class="number">0</span>:<span class="number">32</span>, <span class="number">1</span>:<span class="number">16</span>, <span class="number">2</span>:<span class="number">8</span>&#125;[l] <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(num_layers)]</span><br><span class="line">    <span class="comment">#y_true的格式为（m,13,13,3,85),(m,26,26,3,85),(m,52,52,3,85) num_classes是一个one_hot编码</span></span><br><span class="line">    y_true = [np.zeros((m,grid_shapes[l][<span class="number">0</span>],grid_shapes[l][<span class="number">1</span>],<span class="built_in">len</span>(anchor_mask[l]),<span class="number">5</span>+num_classes),</span><br><span class="line">        dtype=<span class="string">&#x27;float32&#x27;</span>) <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(num_layers)]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Expand dim to apply broadcasting.增加维度是为了更好的计算</span></span><br><span class="line">    anchors = np.expand_dims(anchors, <span class="number">0</span>)<span class="comment">#np.expand_dims(input, dim, name=None)函数,将维度加1</span></span><br><span class="line">    <span class="comment">#anchor/2和取反则是为了计算iou 可以看作把anchor的中心移到坐标原点</span></span><br><span class="line">    anchor_maxes = anchors / <span class="number">2.</span></span><br><span class="line">    anchor_mins = -anchor_maxes</span><br><span class="line">    <span class="comment">#长度要大于0才有效</span></span><br><span class="line">    valid_mask = boxes_wh[..., <span class="number">0</span>]&gt;<span class="number">0</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> b <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        <span class="comment"># Discard zero rows.</span></span><br><span class="line">        wh = boxes_wh[b, valid_mask[b]]</span><br><span class="line">        <span class="keyword">if</span> <span class="built_in">len</span>(wh)==<span class="number">0</span>: <span class="keyword">continue</span></span><br><span class="line">        <span class="comment"># Expand dim to apply broadcasting.</span></span><br><span class="line">        wh = np.expand_dims(wh, -<span class="number">2</span>)</span><br><span class="line">        box_maxes = wh / <span class="number">2.</span></span><br><span class="line">        box_mins = -box_maxes</span><br><span class="line"></span><br><span class="line">        <span class="comment">#计算真实框和哪个先验框最契合、对于有效的边框、采用与anchor相似的处理方法</span></span><br><span class="line">        <span class="comment">#INTERSECT（交集) 集合运算</span></span><br><span class="line">        intersect_mins = np.maximum(box_mins, anchor_mins)</span><br><span class="line">        intersect_maxes = np.minimum(box_maxes, anchor_maxes)</span><br><span class="line">        intersect_wh = np.maximum(intersect_maxes - intersect_mins, <span class="number">0.</span>)</span><br><span class="line">        intersect_area = intersect_wh[..., <span class="number">0</span>] * intersect_wh[..., <span class="number">1</span>]</span><br><span class="line">        box_area = wh[..., <span class="number">0</span>] * wh[..., <span class="number">1</span>]</span><br><span class="line">        anchor_area = anchors[..., <span class="number">0</span>] * anchors[..., <span class="number">1</span>]</span><br><span class="line">        iou = intersect_area / (box_area + anchor_area - intersect_area)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Find best anchor for each true box</span></span><br><span class="line">        best_anchor = np.argmax(iou, axis=-<span class="number">1</span>)<span class="comment">#np.argmax()返回张量沿指定维度最大值的引索</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span> t, n <span class="keyword">in</span> <span class="built_in">enumerate</span>(best_anchor):<span class="comment">#enumerate()是python的内置函数，可遍历每个元素，组合为索引 元素，常在for循环中使用</span></span><br><span class="line">            <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">                <span class="keyword">if</span> n <span class="keyword">in</span> anchor_mask[l]:</span><br><span class="line">                    <span class="comment">#np.floor()返回不大于输入参数的最大整数。（向下取整）</span></span><br><span class="line">                    i = np.floor(true_boxes[b,t,<span class="number">0</span>]*grid_shapes[l][<span class="number">1</span>]).astype(<span class="string">&#x27;int32&#x27;</span>)<span class="comment">#中心点x在grid中的对应位置</span></span><br><span class="line">                    j = np.floor(true_boxes[b,t,<span class="number">1</span>]*grid_shapes[l][<span class="number">0</span>]).astype(<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line">                    k = anchor_mask[l](n)<span class="comment">#返回真实框对应最契合的先验框中</span></span><br><span class="line">                    c = true_boxes[b,t, <span class="number">4</span>].astype(<span class="string">&#x27;int32&#x27;</span>)<span class="comment">#该框所对应的类别</span></span><br><span class="line">                    <span class="comment">#将真实框的信息放进y_true与之对应的特征层的相对应中心点中</span></span><br><span class="line">                    y_true[l][b, j, i, k, <span class="number">0</span>:<span class="number">4</span>] = true_boxes[b,t, <span class="number">0</span>:<span class="number">4</span>]</span><br><span class="line">                    y_true[l][b, j, i, k, <span class="number">4</span>] = <span class="number">1</span></span><br><span class="line">                    y_true[l][b, j, i, k, <span class="number">5</span>+c] = <span class="number">1</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> y_true</span><br></pre></td></tr></table></figure><h3 id="preprocess-true-boxes中涉及到的anchor-box和ground-truth经过-2和取反等处理后，其相对关系应大概如图所示："><a href="#preprocess-true-boxes中涉及到的anchor-box和ground-truth经过-2和取反等处理后，其相对关系应大概如图所示：" class="headerlink" title="preprocess_true_boxes中涉及到的anchor box和ground truth经过&#x2F;2和取反等处理后，其相对关系应大概如图所示："></a>preprocess_true_boxes中涉及到的anchor box和ground truth经过&#x2F;2和取反等处理后，其相对关系应大概如图所示：</h3><p><a href="https://imgtu.com/i/o3Yv7Q"><img src="https://z3.ax1x.com/2021/11/30/o3Yv7Q.png" alt="o3Yv7Q.png"></a></p><h2 id="LOSS值的计算"><a href="#LOSS值的计算" class="headerlink" title="&gt; LOSS值的计算"></a>&gt; LOSS值的计算</h2><h4 id="（1）计算xy（物体中心坐标）的损失：xyloss-bool-2-areaPred-bce"><a href="#（1）计算xy（物体中心坐标）的损失：xyloss-bool-2-areaPred-bce" class="headerlink" title="（1）计算xy（物体中心坐标）的损失：xyloss&#x3D;bool*(2-areaPred)*bce"></a>（1）计算xy（物体中心坐标）的损失：xyloss&#x3D;bool*(2-areaPred)*bce</h4><h4 id="（2）计算wh（anchor长宽回归值）的损失：whloss-bool-2-areaPred-bce"><a href="#（2）计算wh（anchor长宽回归值）的损失：whloss-bool-2-areaPred-bce" class="headerlink" title="（2）计算wh（anchor长宽回归值）的损失：whloss&#x3D;bool*(2-areaPred)*bce"></a>（2）计算wh（anchor长宽回归值）的损失：whloss&#x3D;bool*(2-areaPred)*bce</h4><h4 id="（3）计算置信度的损失：whloss-bool-2-areaPred-bce"><a href="#（3）计算置信度的损失：whloss-bool-2-areaPred-bce" class="headerlink" title="（3）计算置信度的损失：whloss&#x3D;bool*(2-areaPred)*bce"></a>（3）计算置信度的损失：whloss&#x3D;bool*(2-areaPred)*bce</h4><h4 id="（4）计算类别损失：置信度乘上多分类的交叉熵"><a href="#（4）计算类别损失：置信度乘上多分类的交叉熵" class="headerlink" title="（4）计算类别损失：置信度乘上多分类的交叉熵"></a>（4）计算类别损失：置信度乘上多分类的交叉熵</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#定义一个iou函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">box_iou</span>(<span class="params">b1, b2</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Return iou tensor</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    b1: tensor, shape=(i1,...,iN, 4), xywh</span></span><br><span class="line"><span class="string">    b2: tensor, shape=(j, 4), xywh</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    iou: tensor, shape=(i1,...,iN, j)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Expand dim to apply broadcasting.</span></span><br><span class="line">    b1 = K.expand_dims(b1, -<span class="number">2</span>)</span><br><span class="line">    b1_xy = b1[..., :<span class="number">2</span>]</span><br><span class="line">    b1_wh = b1[..., <span class="number">2</span>:<span class="number">4</span>]</span><br><span class="line">    b1_wh_half = b1_wh/<span class="number">2.</span></span><br><span class="line">    b1_mins = b1_xy - b1_wh_half</span><br><span class="line">    b1_maxes = b1_xy + b1_wh_half</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Expand dim to apply broadcasting.</span></span><br><span class="line">    b2 = K.expand_dims(b2, <span class="number">0</span>)</span><br><span class="line">    b2_xy = b2[..., :<span class="number">2</span>]</span><br><span class="line">    b2_wh = b2[..., <span class="number">2</span>:<span class="number">4</span>]</span><br><span class="line">    b2_wh_half = b2_wh/<span class="number">2.</span></span><br><span class="line">    b2_mins = b2_xy - b2_wh_half</span><br><span class="line">    b2_maxes = b2_xy + b2_wh_half</span><br><span class="line"></span><br><span class="line">    intersect_mins = K.maximum(b1_mins, b2_mins)</span><br><span class="line">    intersect_maxes = K.minimum(b1_maxes, b2_maxes)</span><br><span class="line">    intersect_wh = K.maximum(intersect_maxes - intersect_mins, <span class="number">0.</span>)</span><br><span class="line">    intersect_area = intersect_wh[..., <span class="number">0</span>] * intersect_wh[..., <span class="number">1</span>]</span><br><span class="line">    b1_area = b1_wh[..., <span class="number">0</span>] * b1_wh[..., <span class="number">1</span>]</span><br><span class="line">    b2_area = b2_wh[..., <span class="number">0</span>] * b2_wh[..., <span class="number">1</span>]</span><br><span class="line">    iou = intersect_area / (b1_area + b2_area - intersect_area)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> iou</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">yolo_loss</span>(<span class="params">args, anchors, num_classes, ignore_thresh=<span class="number">.5</span>, print_loss=<span class="literal">False</span></span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;Return yolo_loss tensor</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Parameters</span></span><br><span class="line"><span class="string">    ----------</span></span><br><span class="line"><span class="string">    yolo_outputs: list of tensor, the output of yolo_body or tiny_yolo_body</span></span><br><span class="line"><span class="string">    y_true: list of array, the output of preprocess_true_boxes</span></span><br><span class="line"><span class="string">    anchors: array, shape=(N, 2), wh</span></span><br><span class="line"><span class="string">    num_classes: integer</span></span><br><span class="line"><span class="string">    ignore_thresh: float, the iou threshold whether to ignore object confidence loss</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    Returns</span></span><br><span class="line"><span class="string">    -------</span></span><br><span class="line"><span class="string">    loss: tensor, shape=(1,)</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line">    num_layers = <span class="built_in">len</span>(anchors)//<span class="number">3</span> <span class="comment"># default setting</span></span><br><span class="line">    <span class="comment">#将预测结果和实际ground truth分开，args是[*model_body.output,*y_true]</span></span><br><span class="line">    <span class="comment">#y_true是一个列表，包含三个特征层，shape分别为(m,13,13,3,85),(m,26,26,3,85),(m,52,52,3,85)</span></span><br><span class="line">    <span class="comment">#yolo_outputs是一个列表，包含三个特征层，shape分别为(m,13,13,3,85),(m,26,26,3,85),(m,52,52,3,85)</span></span><br><span class="line">    yolo_outputs = args[:num_layers]</span><br><span class="line">    y_true = args[num_layers:]</span><br><span class="line">    anchor_mask = [[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>], [<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>], [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]] <span class="keyword">if</span> num_layers==<span class="number">3</span> <span class="keyword">else</span> [[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>], [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]]</span><br><span class="line">    input_shape = K.cast(K.shape(yolo_outputs[<span class="number">0</span>])[<span class="number">1</span>:<span class="number">3</span>] * <span class="number">32</span>, K.dtype(y_true[<span class="number">0</span>]))</span><br><span class="line">    grid_shapes = [K.cast(K.shape(yolo_outputs[l])[<span class="number">1</span>:<span class="number">3</span>], K.dtype(y_true[<span class="number">0</span>])) <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(num_layers)]</span><br><span class="line">    loss = <span class="number">0</span></span><br><span class="line">    m = K.shape(yolo_outputs[<span class="number">0</span>])[<span class="number">0</span>] <span class="comment"># batch size, tensor</span></span><br><span class="line">    mf = K.cast(m, K.dtype(yolo_outputs[<span class="number">0</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">        <span class="comment">#取出其对应的种类(m,X,X,3,1)</span></span><br><span class="line">        object_mask = y_true[l][..., <span class="number">4</span>:<span class="number">5</span>]<span class="comment">#obiect_mask就是置信度</span></span><br><span class="line">        <span class="comment">#取出其对应的种类(m,X,X,3,80)</span></span><br><span class="line">        true_class_probs = y_true[l][..., <span class="number">5</span>:]</span><br><span class="line">        <span class="comment">#将yolo_outputs的特征层输出进行处理</span></span><br><span class="line">        <span class="comment">#grid为网格结构(x,x,1,2),raw_pred为尚未处理的预测结果(m,x,x,3,85)</span></span><br><span class="line">        <span class="comment">#还有解码后的xy，wh，(m,13,13,3,2)</span></span><br><span class="line">        grid, raw_pred, pred_xy, pred_wh = yolo_head(yolo_outputs[l],</span><br><span class="line">             anchors[anchor_mask[l]], num_classes, input_shape, calc_loss=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment">#解码后的预测的box的位置</span></span><br><span class="line">        <span class="comment">#(m,13,13,3,4)</span></span><br><span class="line">        pred_box = K.concatenate([pred_xy, pred_wh])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Darknet raw box to calculate loss.</span></span><br><span class="line">        raw_true_xy = y_true[l][..., :<span class="number">2</span>]*grid_shapes[l][::-<span class="number">1</span>] - grid</span><br><span class="line">        raw_true_wh = K.log(y_true[l][..., <span class="number">2</span>:<span class="number">4</span>] / anchors[anchor_mask[l]] * input_shape[::-<span class="number">1</span>])</span><br><span class="line">        raw_true_wh = K.switch(object_mask, raw_true_wh, K.zeros_like(raw_true_wh)) <span class="comment"># avoid log(0)=-inf#switch接口，就是一个if/else条件判断语句</span></span><br><span class="line">        box_loss_scale = <span class="number">2</span> - y_true[l][...,<span class="number">2</span>:<span class="number">3</span>]*y_true[l][...,<span class="number">3</span>:<span class="number">4</span>]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Find ignore mask, iterate over each of batch.</span></span><br><span class="line">        ignore_mask = tf.TensorArray(K.dtype(y_true[<span class="number">0</span>]), size=<span class="number">1</span>, dynamic_size=<span class="literal">True</span>)</span><br><span class="line">        object_mask_bool = K.cast(object_mask, <span class="string">&#x27;bool&#x27;</span>)</span><br><span class="line">        <span class="keyword">def</span> <span class="title function_">loop_body</span>(<span class="params">b, ignore_mask</span>):</span><br><span class="line">            true_box = tf.boolean_mask(y_true[l][b,...,<span class="number">0</span>:<span class="number">4</span>], object_mask_bool[b,...,<span class="number">0</span>])</span><br><span class="line">            <span class="comment">#计算预测结果与真实情况的iou</span></span><br><span class="line">            <span class="comment">#pred_box为13，13，3，4</span></span><br><span class="line">            <span class="comment">#计算的结果是每个pred_box和其它所有真实框的iou</span></span><br><span class="line">            <span class="comment">#13，13，3，n</span></span><br><span class="line">            iou = box_iou(pred_box[b], true_box)</span><br><span class="line">            best_iou = K.<span class="built_in">max</span>(iou, axis=-<span class="number">1</span>)</span><br><span class="line">            ignore_mask = ignore_mask.write(b, K.cast(best_iou&lt;ignore_thresh, K.dtype(true_box)))</span><br><span class="line">            <span class="keyword">return</span> b+<span class="number">1</span>, ignore_mask</span><br><span class="line">        <span class="comment">#遍历所有图片</span></span><br><span class="line">        _, ignore_mask = K.control_flow_ops.while_loop(<span class="keyword">lambda</span> b,*args: b&lt;m, loop_body, [<span class="number">0</span>, ignore_mask])<span class="comment">#K.control_flow_ops.while_loop(cond, body, loop_vars)，其中cond是条件判断函数，返回True或False; body是循环体；loop_vars是传入cond和body的参数列表。</span></span><br><span class="line">        <span class="comment">#将每幅图的内容压缩，进行处理</span></span><br><span class="line">        ignore_mask = ignore_mask.stack()</span><br><span class="line">        <span class="comment">#(m,13,13,3,1,1)</span></span><br><span class="line">        ignore_mask = K.expand_dims(ignore_mask, -<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># K.binary_crossentropy is helpful to avoid exp overflow.</span></span><br><span class="line">        xy_loss = object_mask * box_loss_scale * K.binary_crossentropy(raw_true_xy, raw_pred[...,<span class="number">0</span>:<span class="number">2</span>], from_logits=<span class="literal">True</span>)</span><br><span class="line">        wh_loss = object_mask * box_loss_scale * <span class="number">0.5</span> * K.square(raw_true_wh-raw_pred[...,<span class="number">2</span>:<span class="number">4</span>])</span><br><span class="line">        <span class="comment">#如果该位置本来有框，那么计算1与置信度的交叉熵</span></span><br><span class="line">        <span class="comment">#如果该位置本来没有框，而且满足best_iou&lt;ignore_thresh，则被认定为负样本</span></span><br><span class="line">        <span class="comment">#best_iou&lt;ignore_thresh用于限制负样本</span></span><br><span class="line">        confidence_loss = object_mask * K.binary_crossentropy(object_mask, raw_pred[...,<span class="number">4</span>:<span class="number">5</span>], from_logits=<span class="literal">True</span>)</span><br><span class="line">            (<span class="number">1</span>-object_mask) * K.binary_crossentropy(object_mask, raw_pred[...,<span class="number">4</span>:<span class="number">5</span>], from_logits=<span class="literal">True</span>) * ignore_mask</span><br><span class="line">        class_loss = object_mask * K.binary_crossentropy(true_class_probs, raw_pred[...,<span class="number">5</span>:], from_logits=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">        xy_loss = K.<span class="built_in">sum</span>(xy_loss) / mf</span><br><span class="line">        wh_loss = K.<span class="built_in">sum</span>(wh_loss) / mf</span><br><span class="line">        confidence_loss = K.<span class="built_in">sum</span>(confidence_loss) / mf</span><br><span class="line">        class_loss = K.<span class="built_in">sum</span>(class_loss) / mf</span><br><span class="line">        loss += xy_loss + wh_loss + confidence_loss + class_loss</span><br><span class="line">        <span class="keyword">if</span> print_loss:</span><br><span class="line">            loss = tf.Print(loss, [loss, xy_loss, wh_loss, confidence_loss, class_loss, K.<span class="built_in">sum</span>(ignore_mask)], message=<span class="string">&#x27;loss: &#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure><h3 id="在loss值的计算过程中预测框被分为三类："><a href="#在loss值的计算过程中预测框被分为三类：" class="headerlink" title="在loss值的计算过程中预测框被分为三类："></a>在loss值的计算过程中预测框被分为三类：</h3><h4 id="正例：任取一个ground-truth，与4032个框全部计算IOU，IOU最大的预测框，即为正例。并且一个预测框，只能分配给一个ground-truth。例如第一个ground-truth已经匹配了一个正例检测框，那么下一个ground-truth，就在余下的4031个检测框中，寻找IOU最大的检测框作为正例。ground-truth的先后顺序可忽略。正例产生置信度loss、检测框loss、类别loss。预测框为对应的ground-truth-box标签（需要反向编码，使用真实的x、y、w、h计算出-公式-）；类别标签对应类别为1，其余为0；置信度标签为1。"><a href="#正例：任取一个ground-truth，与4032个框全部计算IOU，IOU最大的预测框，即为正例。并且一个预测框，只能分配给一个ground-truth。例如第一个ground-truth已经匹配了一个正例检测框，那么下一个ground-truth，就在余下的4031个检测框中，寻找IOU最大的检测框作为正例。ground-truth的先后顺序可忽略。正例产生置信度loss、检测框loss、类别loss。预测框为对应的ground-truth-box标签（需要反向编码，使用真实的x、y、w、h计算出-公式-）；类别标签对应类别为1，其余为0；置信度标签为1。" class="headerlink" title="正例：任取一个ground truth，与4032个框全部计算IOU，IOU最大的预测框，即为正例。并且一个预测框，只能分配给一个ground truth。例如第一个ground truth已经匹配了一个正例检测框，那么下一个ground truth，就在余下的4031个检测框中，寻找IOU最大的检测框作为正例。ground truth的先后顺序可忽略。正例产生置信度loss、检测框loss、类别loss。预测框为对应的ground truth box标签（需要反向编码，使用真实的x、y、w、h计算出 [公式] ）；类别标签对应类别为1，其余为0；置信度标签为1。"></a>正例：任取一个ground truth，与4032个框全部计算IOU，IOU最大的预测框，即为正例。并且一个预测框，只能分配给一个ground truth。例如第一个ground truth已经匹配了一个正例检测框，那么下一个ground truth，就在余下的4031个检测框中，寻找IOU最大的检测框作为正例。ground truth的先后顺序可忽略。正例产生置信度loss、检测框loss、类别loss。预测框为对应的ground truth box标签（需要反向编码，使用真实的x、y、w、h计算出 [公式] ）；类别标签对应类别为1，其余为0；置信度标签为1。</h4><h4 id="忽略样例：正例除外，与任意一个ground-truth的IOU大于阈值（论文中使用0-5），则为忽略样例。忽略样例不产生任何loss。（存在意义：由于Yolov3使用了多尺度特征图，不同尺度的特征图之间会有重合检测部分。比如有一个真实物体，在训练时被分配到的检测框是特征图1的第三个box，IOU达0-98，此时恰好特征图2的第一个box与该ground-truth的IOU达0-95，也检测到了该ground-truth，如果此时给其置信度强行打0的标签，网络学习效果会不理想。）"><a href="#忽略样例：正例除外，与任意一个ground-truth的IOU大于阈值（论文中使用0-5），则为忽略样例。忽略样例不产生任何loss。（存在意义：由于Yolov3使用了多尺度特征图，不同尺度的特征图之间会有重合检测部分。比如有一个真实物体，在训练时被分配到的检测框是特征图1的第三个box，IOU达0-98，此时恰好特征图2的第一个box与该ground-truth的IOU达0-95，也检测到了该ground-truth，如果此时给其置信度强行打0的标签，网络学习效果会不理想。）" class="headerlink" title="忽略样例：正例除外，与任意一个ground truth的IOU大于阈值（论文中使用0.5），则为忽略样例。忽略样例不产生任何loss。（存在意义：由于Yolov3使用了多尺度特征图，不同尺度的特征图之间会有重合检测部分。比如有一个真实物体，在训练时被分配到的检测框是特征图1的第三个box，IOU达0.98，此时恰好特征图2的第一个box与该ground truth的IOU达0.95，也检测到了该ground truth，如果此时给其置信度强行打0的标签，网络学习效果会不理想。）"></a>忽略样例：正例除外，与任意一个ground truth的IOU大于阈值（论文中使用0.5），则为忽略样例。忽略样例不产生任何loss。（存在意义：由于Yolov3使用了多尺度特征图，不同尺度的特征图之间会有重合检测部分。比如有一个真实物体，在训练时被分配到的检测框是特征图1的第三个box，IOU达0.98，此时恰好特征图2的第一个box与该ground truth的IOU达0.95，也检测到了该ground truth，如果此时给其置信度强行打0的标签，网络学习效果会不理想。）</h4><h4 id="负例：正例除外（与ground-truth计算后IOU最大的检测框，但是IOU小于阈值，仍为正例），与全部ground-truth的IOU都小于阈值（0-5），则为负例。负例只有置信度产生loss，置信度标签为0。"><a href="#负例：正例除外（与ground-truth计算后IOU最大的检测框，但是IOU小于阈值，仍为正例），与全部ground-truth的IOU都小于阈值（0-5），则为负例。负例只有置信度产生loss，置信度标签为0。" class="headerlink" title="负例：正例除外（与ground truth计算后IOU最大的检测框，但是IOU小于阈值，仍为正例），与全部ground truth的IOU都小于阈值（0.5），则为负例。负例只有置信度产生loss，置信度标签为0。"></a>负例：正例除外（与ground truth计算后IOU最大的检测框，但是IOU小于阈值，仍为正例），与全部ground truth的IOU都小于阈值（0.5），则为负例。负例只有置信度产生loss，置信度标签为0。</h4><h2 id="图片预测"><a href="#图片预测" class="headerlink" title="&gt; 图片预测"></a>&gt; 图片预测</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">yolo_eval</span>(<span class="params">yolo_outputs,</span></span><br><span class="line"><span class="params">              anchors,</span></span><br><span class="line"><span class="params">              num_classes,</span></span><br><span class="line"><span class="params">              image_shape,</span></span><br><span class="line"><span class="params">              max_boxes=<span class="number">20</span>,</span></span><br><span class="line"><span class="params">              score_threshold=<span class="number">.6</span>,</span></span><br><span class="line"><span class="params">              iou_threshold=<span class="number">.5</span></span>):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;Evaluate YOLO model on given input and return filtered boxes.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="comment">#获得特征层的数量</span></span><br><span class="line">    num_layers = <span class="built_in">len</span>(yolo_outputs)</span><br><span class="line">    <span class="comment">#特征层1对应的anchor是678</span></span><br><span class="line">    <span class="comment">#特征层2对应的anchor是345</span></span><br><span class="line">    <span class="comment">#特征层3对应的anchor是012</span></span><br><span class="line">    anchor_mask = [[<span class="number">6</span>,<span class="number">7</span>,<span class="number">8</span>], [<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>], [<span class="number">0</span>,<span class="number">1</span>,<span class="number">2</span>]] <span class="keyword">if</span> num_layers==<span class="number">3</span> <span class="keyword">else</span> [[<span class="number">3</span>,<span class="number">4</span>,<span class="number">5</span>], [<span class="number">1</span>,<span class="number">2</span>,<span class="number">3</span>]] <span class="comment"># default setting</span></span><br><span class="line">    input_shape = K.shape(yolo_outputs[<span class="number">0</span>])[<span class="number">1</span>:<span class="number">3</span>] * <span class="number">32</span></span><br><span class="line">    boxes = []</span><br><span class="line">    box_scores = []</span><br><span class="line">    <span class="comment">#对每个特征层进行处理</span></span><br><span class="line">    <span class="keyword">for</span> l <span class="keyword">in</span> <span class="built_in">range</span>(num_layers):</span><br><span class="line">        _boxes, _box_scores = yolo_boxes_and_scores(yolo_outputs[l],</span><br><span class="line">            anchors[anchor_mask[l]], num_classes, input_shape, image_shape)</span><br><span class="line">        boxes.append(_boxes)</span><br><span class="line">        box_scores.append(_box_scores)</span><br><span class="line">    <span class="comment">#将每个特征层结果进行堆叠</span></span><br><span class="line">    boxes = K.concatenate(boxes, axis=<span class="number">0</span>)</span><br><span class="line">    box_scores = K.concatenate(box_scores, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    mask = box_scores &gt;= score_threshold</span><br><span class="line">    max_boxes_tensor = K.constant(max_boxes, dtype=<span class="string">&#x27;int32&#x27;</span>)</span><br><span class="line">    boxes_ = []</span><br><span class="line">    scores_ = []</span><br><span class="line">    classes_ = []</span><br><span class="line">    <span class="keyword">for</span> c <span class="keyword">in</span> <span class="built_in">range</span>(num_classes):</span><br><span class="line">        <span class="comment"># <span class="doctag">TODO:</span> use keras backend instead of tf.</span></span><br><span class="line">        <span class="comment">#取出所有box_scores&gt;=score_threshold的框和成绩</span></span><br><span class="line">        class_boxes = tf.boolean_mask(boxes, mask[:, c])<span class="comment">#tf.boolean_mask 的作用是 通过布尔值 过滤元素tensor：被过滤的元素mask：一堆 bool 值，它的维度不一定等于 tensorreturn： mask 为 true 对应的 tensor 的元素当 tensor 与 mask 维度一致时，return 一维</span></span><br><span class="line">        class_box_scores = tf.boolean_mask(box_scores[:, c], mask[:, c])</span><br><span class="line">        <span class="comment">#非极大抑制</span></span><br><span class="line">        nms_index = tf.image.non_max_suppression(</span><br><span class="line">            class_boxes, class_box_scores, max_boxes_tensor, iou_threshold=iou_threshold)</span><br><span class="line">        <span class="comment">#获得非极大值抑制后的结果</span></span><br><span class="line">        <span class="comment">#下列三个分别是：框的位置，得分与种类</span></span><br><span class="line">        class_boxes = K.gather(class_boxes, nms_index)</span><br><span class="line">        class_box_scores = K.gather(class_box_scores, nms_index)<span class="comment">#gather（reference,indices)在给定的张量中搜索给定下标的向量。</span></span><br><span class="line">        classes = K.ones_like(class_box_scores, <span class="string">&#x27;int32&#x27;</span>) * c<span class="comment">#ones_like给定一个tensor（tensor 参数），该操作返回一个具有和给定tensor相同形状（shape）和相同数据类型（dtype），但是所有的元素都被设置为1的tensor。</span></span><br><span class="line">        boxes_.append(class_boxes)</span><br><span class="line">        scores_.append(class_box_scores)</span><br><span class="line">        classes_.append(classes)</span><br><span class="line">    boxes_ = K.concatenate(boxes_, axis=<span class="number">0</span>)</span><br><span class="line">    scores_ = K.concatenate(scores_, axis=<span class="number">0</span>)</span><br><span class="line">    classes_ = K.concatenate(classes_, axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> boxes_, scores_, classes_</span><br></pre></td></tr></table></figure>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;YOLOv3-model-py代码的简单分析注解&quot;&gt;&lt;a href=&quot;#YOLOv3-model-py代码的简单分析注解&quot; class=&quot;headerlink&quot; title=&quot;YOLOv3 model.py代码的简单分析注解&quot;&gt;&lt;/a&gt;YOLOv3 model.p</summary>
      
    
    
    
    <category term="Yolo学习" scheme="http://example.com/categories/Yolo%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>yolov2做出的改进</title>
    <link href="http://example.com/wiki/Yolo%E5%AD%A6%E4%B9%A0/yolov2%E5%81%9A%E5%87%BA%E7%9A%84%E6%94%B9%E8%BF%9B/"/>
    <id>http://example.com/wiki/Yolo%E5%AD%A6%E4%B9%A0/yolov2%E5%81%9A%E5%87%BA%E7%9A%84%E6%94%B9%E8%BF%9B/</id>
    <published>2025-08-15T08:34:27.000Z</published>
    <updated>2025-08-24T20:16:56.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="yolov1的缺点"><a href="#yolov1的缺点" class="headerlink" title="yolov1的缺点"></a>yolov1的缺点</h1><p>YOLOv1虽然检测速度很快，但是在检测精度上却不如R-CNN系检测方法，YOLOv1在物体定位方面（localization）不够准确，并且召回率（recall）较低。</p><h1 id="解决方法"><a href="#解决方法" class="headerlink" title="解决方法"></a>解决方法</h1><h3 id="1-Batch-Normaliza"><a href="#1-Batch-Normaliza" class="headerlink" title="1.Batch Normaliza"></a>1.Batch Normaliza</h3><p>Batch Normalization可以提升模型收敛速度，而且可以起到一定正则化效果，降低模型的过拟合。在YOLOv2中，每个卷积层后面都添加了Batch Normalization层，并且不再使用droput。使用Batch Normalization后，YOLOv2的mAP提升了2.4%。</p><h3 id="2-High-Resolution-Classifier"><a href="#2-High-Resolution-Classifier" class="headerlink" title="2.High Resolution Classifier"></a>2.<strong>High Resolution Classifier</strong></h3><p>用更高分辨率的输入（448x448）之前是（224x224）。</p><h3 id="3-Convolutional-With-Anchor-Boxes"><a href="#3-Convolutional-With-Anchor-Boxes" class="headerlink" title="3.Convolutional With Anchor Boxes"></a>3.<strong>Convolutional With Anchor Boxes</strong></h3><h4 id="以前-yolo1存在的问题"><a href="#以前-yolo1存在的问题" class="headerlink" title="以前 yolo1存在的问题"></a>以前 yolo1存在的问题</h4><p>在YOLOv1中，输入图片最终被划分为$7\times 7$ 网格，每个单元格预测2个边界框。YOLOv1最后采用的是全连接层直接对边界框进行预测，其中边界框的宽与高是相对整张图片大小的，而由于各个图片中存在不同尺度和长宽比（scales and ratios)的物体，YOLOv1在训练过程中学习适应不同物体的形状是比较困难的，这也导致YOLOv1在精确定位方面表现较差。</p><h4 id="改进思路"><a href="#改进思路" class="headerlink" title="改进思路"></a>改进思路</h4><p>用anchor boxes（先验框）</p><p>采用先验框使得模型更容易学习。所以YOLOv2移除了YOLOv1中的全连接层而采用了卷积和anchor boxes来预测边界框。</p><h4 id="效果"><a href="#效果" class="headerlink" title="效果"></a>效果</h4><p>使用anchor boxes之后，YOLOv2的mAP有稍微下降（这里下降的原因，我猜想是YOLOv2虽然使用了anchor boxes，但是依然采用YOLOv1的训练方法）。YOLOv1只能预测98个边界框（ <img src="https://www.zhihu.com/equation?tex=7%5Ctimes7%5Ctimes2" alt="[公式]"> ），而YOLOv2使用anchor boxes之后可以预测上千个边界框（ <img src="https://www.zhihu.com/equation?tex=13%5Ctimes13%5Ctimes%5Ctext%7Bnum_anchors%7D" alt="[公式]"> )。所以使用anchor boxes之后，YOLOv2的召回率大大提升，由原来的81%升至88%。</p><h3 id="4-Dimension-Clusters"><a href="#4-Dimension-Clusters" class="headerlink" title="4.Dimension Clusters"></a>4.<strong>Dimension Clusters</strong></h3><p>先验框的维度（长和宽）都是手动设定的，带有一定的主观性。如果选取的先验框维度比较合适，那么模型更容易学习，从而做出更好的预测。因此，YOLOv2采用k-means聚类方法对训练集中的边界框做了聚类分析。</p><p><strong>聚类分析怎么做的我还没有看</strong></p><p>因为设置先验框的主要目的是为了使得预测框与ground truth的IOU更好，所以聚类分析时选用box与聚类中心box之间的IOU值作为距离指标：</p><p><img src="https://www.zhihu.com/equation?tex=d(box,+centroid)+=+1+-+IOU(box,+centroid)" alt="[公式]"></p><h3 id="5-New-Network-Darknet-19"><a href="#5-New-Network-Darknet-19" class="headerlink" title="5.New Network: Darknet-19"></a>5.<strong>New Network: Darknet-19</strong></h3><p>YOLOv2采用了一个新的基础模型（特征提取器），称为Darknet-19，包括19个卷积层和5个maxpooling层，如图4所示。Darknet-19与VGG16模型设计原则是一致的，主要采用 <img src="https://www.zhihu.com/equation?tex=3%5Ctimes3" alt="[公式]"> 卷积，采用 <img src="https://www.zhihu.com/equation?tex=2%5Ctimes2" alt="[公式]"> 的maxpooling层之后，特征图维度降低2倍，而同时将特征图的channles增加两倍。与NIN(<a href="https://link.zhihu.com/?target=https://arxiv.org/abs/1312.4400">Network in Network</a>)类似，Darknet-19最终采用global avgpooling做预测，并且在 <img src="https://www.zhihu.com/equation?tex=3%5Ctimes3" alt="[公式]"> 卷积之间使用 <img src="https://www.zhihu.com/equation?tex=1%5Ctimes1" alt="[公式]"> 卷积来压缩特征图channles以降低模型计算量和参数。Darknet-19每个卷积层后面同样使用了batch norm层以加快收敛速度，降低模型过拟合。</p><h4 id="性能提升"><a href="#性能提升" class="headerlink" title="性能提升"></a>性能提升</h4><p>在ImageNet分类数据集上，Darknet-19的top-1准确度为72.9%，top-5准确度为91.2%，但是模型参数相对小一些。使用Darknet-19之后，YOLOv2的mAP值没有显著提升，但是计算量却可以减少约33%。</p><h3 id="6-Direct-location-prediction"><a href="#6-Direct-location-prediction" class="headerlink" title="6.Direct location prediction"></a>6.<strong>Direct location prediction</strong></h3><p>前面讲到，YOLOv2借鉴RPN网络使用anchor boxes来预测边界框相对先验框的offsets。边界框的实际中心位置 <img src="https://www.zhihu.com/equation?tex=(x,y)" alt="[公式]"> ，需要根据预测的坐标偏移值 <img src="https://www.zhihu.com/equation?tex=(t_x,+t_y)" alt="[公式]"> ，先验框的尺度 <img src="https://www.zhihu.com/equation?tex=(w_a,+h_a)" alt="[公式]"> 以及中心坐标 <img src="https://www.zhihu.com/equation?tex=(x_a,+y_a)" alt="[公式]"> （特征图每个位置的中心点）来计算：</p><p><img src="https://www.zhihu.com/equation?tex=%5C%5Cx+=+(t_x%5Ctimes+w_a)-x_a" alt="[公式]"></p><p><img src="https://www.zhihu.com/equation?tex=%5C%5Cy=(t_y%5Ctimes+h_a)+-+y_a" alt="[公式]"></p><p>但是上面的公式是无约束的，预测的边界框很容易向任何方向偏移，如当 <img src="https://www.zhihu.com/equation?tex=t_x=1" alt="[公式]"> 时边界框将向右偏移先验框的一个宽度大小，而当 <img src="https://www.zhihu.com/equation?tex=t_x=-1" alt="[公式]"> 时边界框将向左偏移先验框的一个宽度大小，因此每个位置预测的边界框可以落在图片任何位置，这导致模型的不稳定性，在训练时需要很长时间来预测出正确的offsets。</p><p>所以，YOLOv2弃用了这种预测方式，而是沿用YOLOv1的方法，就是<strong>预测边界框中心点相对于对应cell左上角位置的相对偏移值</strong>，为了<strong>将边界框中心点约束在当前cell中，使用sigmoid函数处理偏移值</strong>，这样预测的偏移值在(0,1)范围内（每个cell的尺度看做1）。总结来看，根据边界框预测的4个offsets <img src="https://www.zhihu.com/equation?tex=t_x,+t_y,+t_w,+t_h" alt="[公式]"> ，可以按如下公式计算出边界框实际位置和大小：</p><p><img src="https://www.zhihu.com/equation?tex=%5C%5Cb_x+=+%5Csigma+(t_x)+c_x" alt="[公式]"></p><p><img src="https://www.zhihu.com/equation?tex=%5C%5Cb_y+=+%5Csigma+(t_y)+++c_y" alt="[公式]"></p><p><img src="https://www.zhihu.com/equation?tex=%5C%5Cb_w+=+p_we%5E%7Bt_w%7D" alt="[公式]"></p><p><img src="https://www.zhihu.com/equation?tex=%5C%5Cb_h+=+p_he%5E%7Bt_h%7D" alt="[公式]"></p><p>其中 <img src="https://www.zhihu.com/equation?tex=(c_x,+x_y)" alt="[公式]"> 为cell的左上角坐标，如图5所示，在计算时每个cell的尺度为1，所以当前cell的左上角坐标为 <img src="https://www.zhihu.com/equation?tex=(1,1)" alt="[公式]"> 。由于sigmoid函数的处理，边界框的中心位置会约束在当前cell内部，防止偏移过多。而 <img src="https://www.zhihu.com/equation?tex=p_w" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=p_h" alt="[公式]"> 是先验框的宽度与长度，前面说过它们的值也是相对于特征图大小的，在特征图中每个cell的长和宽均为1。这里记特征图的大小为 <img src="https://www.zhihu.com/equation?tex=(W,+H)" alt="[公式]"> （在文中是 <img src="https://www.zhihu.com/equation?tex=(13,+13)" alt="[公式]"> )，这样我们可以将边界框相对于整张图片的位置和大小计算出来（4个值均在0和1之间）：</p><p><img src="https://www.zhihu.com/equation?tex=%5C%5Cb_x+=+(%5Csigma+(t_x)+c_x)/W" alt="[公式]"></p><p><img src="https://www.zhihu.com/equation?tex=%5C%5C+b_y+=+(%5Csigma+(t_y)+++c_y)/H" alt="[公式]"></p><p><img src="https://www.zhihu.com/equation?tex=%5C%5Cb_w+=+p_we%5E%7Bt_w%7D/W" alt="[公式]"></p><p><img src="https://www.zhihu.com/equation?tex=+%5C%5Cb_h+=+p_he%5E%7Bt_h%7D/H" alt="[公式]"></p><p>如果再将上面的4个值分别乘以图片的宽度和长度（像素点值）就可以得到边界框的最终位置和大小了。这就是YOLOv2边界框的整个解码过程。约束了边界框的位置预测值使得模型更容易稳定训练，结合聚类分析得到先验框与这种预测方法，YOLOv2的mAP值提升了约5%。</p><p><img src="https://pic3.zhimg.com/v2-7fee941c2e347efc2a3b19702a4acd8e_r.jpg" alt="preview"></p><h3 id="7-Fine-Grained-Features"><a href="#7-Fine-Grained-Features" class="headerlink" title="7.Fine-Grained Features"></a>7.<strong>Fine-Grained Features</strong></h3><p>YOLOv2的输入图片大小为$416\times 416$  ，经过5次maxpooling之后得到$13\times 13$大小的特征图，并以此特征图采用卷积做预测。<img src="https://www.zhihu.com/equation?tex=13%5Ctimes13" alt="[公式]"> 大小的特征图对检测大物体是足够了，但是对于小物体还需要更精细的特征图（Fine-Grained Features)。</p><p>YOLOv2所利用的Fine-Grained Features是 <img src="https://www.zhihu.com/equation?tex=26%5Ctimes26" alt="[公式]"> 大小的特征图（最后一个maxpooling层的输入），对于Darknet-19模型来说就是大小为 <img src="https://www.zhihu.com/equation?tex=26%5Ctimes26%5Ctimes512" alt="[公式]"> 的特征图。passthrough层与ResNet网络的shortcut类似，以前面更高分辨率的特征图为输入，然后将其连接到后面的低分辨率特征图上。前面的特征图维度是后面的特征图的2倍，passthrough层抽取前面层的每个 <img src="https://www.zhihu.com/equation?tex=2%5Ctimes2" alt="[公式]"> 的局部区域，然后将其转化为channel维度，对于 <img src="https://www.zhihu.com/equation?tex=26%5Ctimes26%5Ctimes512" alt="[公式]"> 的特征图，经passthrough层处理之后就变成了 <img src="https://www.zhihu.com/equation?tex=13%5Ctimes13%5Ctimes2048" alt="[公式]"> 的新特征图（特征图大小降低4倍，而channles增加4倍，图6为一个实例），这样就可以与后面的 <img src="https://www.zhihu.com/equation?tex=13%5Ctimes13%5Ctimes1024" alt="[公式]"> 特征图连接在一起形成 <img src="https://www.zhihu.com/equation?tex=13%5Ctimes13%5Ctimes3072" alt="[公式]"> 大小的特征图，然后在此特征图基础上卷积做预测。</p><p><img src="https://pic3.zhimg.com/v2-c94c787a81c1216d8963f7c173c6f086_r.jpg" alt="preview"></p><p>另外，作者在后期的实现中借鉴了ResNet网络，不是直接对高分辨特征图处理，而是增加了一个中间卷积层，先采用64个 <img src="https://www.zhihu.com/equation?tex=1%5Ctimes1" alt="[公式]"> 卷积核进行卷积，然后再进行passthrough处理，这样 <img src="https://www.zhihu.com/equation?tex=26%5Ctimes26%5Ctimes512" alt="[公式]"> 的特征图得到 <img src="https://www.zhihu.com/equation?tex=13%5Ctimes13%5Ctimes256" alt="[公式]"> 的特征图。这算是实现上的一个小细节。使用Fine-Grained Features之后YOLOv2的性能有1%的提升。</p><h3 id="8-Multi-Scale-Training"><a href="#8-Multi-Scale-Training" class="headerlink" title="8.Multi-Scale Training"></a>8.<strong>Multi-Scale Training</strong></h3><p>由于YOLOv2模型中只有卷积层和池化层，所以YOLOv2的输入可以不限于 <img src="https://www.zhihu.com/equation?tex=416%5Ctimes416" alt="[公式]"> 大小的图片。为了增强模型的鲁棒性，YOLOv2采用了多尺度输入训练策略，具体来说就是在训练过程中每间隔一定的iterations之后改变模型的输入图片大小。</p><p>由于YOLOv2的下采样总步长为32，输入图片大小选择一系列为32倍数的值： <img src="https://www.zhihu.com/equation?tex=%5C%7B320,+352,...,+608%5C%7D" alt="[公式]"> ，输入图片最小为 <img src="https://www.zhihu.com/equation?tex=320%5Ctimes320" alt="[公式]"> ，此时对应的特征图大小为 <img src="https://www.zhihu.com/equation?tex=10%5Ctimes10" alt="[公式]"> （不是奇数了，确实有点尴尬），而输入图片最大为 <img src="https://www.zhihu.com/equation?tex=608%5Ctimes608" alt="[公式]"> ，对应的特征图大小为 <img src="https://www.zhihu.com/equation?tex=19%5Ctimes19" alt="[公式]"> 。在训练过程，每隔10个iterations随机选择一种输入图片大小，然后只需要修改对最后检测层的处理就可以重新训练。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;yolov1的缺点&quot;&gt;&lt;a href=&quot;#yolov1的缺点&quot; class=&quot;headerlink&quot; title=&quot;yolov1的缺点&quot;&gt;&lt;/a&gt;yolov1的缺点&lt;/h1&gt;&lt;p&gt;YOLOv1虽然检测速度很快，但是在检测精度上却不如R-CNN系检测方法，YOLOv</summary>
      
    
    
    
    <category term="Yolo学习" scheme="http://example.com/categories/Yolo%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>yolo1 思想与输出的形式</title>
    <link href="http://example.com/wiki/Yolo%E5%AD%A6%E4%B9%A0/yolo1%20%E6%80%9D%E6%83%B3%E4%B8%8E%E8%BE%93%E5%87%BA%E7%9A%84%E5%BD%A2%E5%BC%8F/"/>
    <id>http://example.com/wiki/Yolo%E5%AD%A6%E4%B9%A0/yolo1%20%E6%80%9D%E6%83%B3%E4%B8%8E%E8%BE%93%E5%87%BA%E7%9A%84%E5%BD%A2%E5%BC%8F/</id>
    <published>2025-08-13T10:34:27.000Z</published>
    <updated>2025-08-24T20:06:06.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="只说结论"><a href="#只说结论" class="headerlink" title="只说结论"></a>只说结论</h1><p>yolo1 将一张图片分割为S*S个单元格，每个单元格输出<strong>（Bx5+C）</strong>个值。</p><p>解释： </p><p><strong>B</strong>：每个单元格将会预测B个边框。（就是圈B个框框）</p><p><strong>5</strong>：每个圈出来的框框有5个参数 <img src="https://www.zhihu.com/equation?tex=(x,y,w,h,c)" alt="[公式]"> ，其中前四个是相对于单元格的比例（就是0到1之间的数)。c代表该单元格的置信度。用<strong>该单元格含有目标的概率</strong>与<strong>准确度</strong>的<strong>乘积</strong>表示。</p><p><strong>C</strong>: <strong>one-hot</strong>编码的属于C个类别的预测值。</p><p><strong>所有单元格</strong>的就是<strong>S*S（Bx5+C）</strong>个值</p><h1 id="非极大值抑制算法（non-maximum-suppression-NMS）"><a href="#非极大值抑制算法（non-maximum-suppression-NMS）" class="headerlink" title="非极大值抑制算法（non maximum suppression, NMS）"></a>非极大值抑制算法（non maximum suppression, NMS）</h1><p>这个算法不单单是针对Yolo算法的，而是所有的检测算法中都会用到。NMS算法主要解决的是一个目标被多次检测的问题，如人脸检测，可以看到人脸被多次检测，但是其实我们希望最后仅仅输出其中一个最好的预测框。</p><p>首先从所有的检测框中找到置信度最大的那个框，然后挨个计算其与剩余框的IOU（个人理解为重合区域比例），如果其值大于一定阈值（重合度过高），那么就将该框剔除；然后对剩余的检测框重复上述过程，直到处理完所有的检测框。Yolo预测过程也需要用到NMS算法。</p><h1 id="滑动窗口与CNN"><a href="#滑动窗口与CNN" class="headerlink" title="滑动窗口与CNN"></a>滑动窗口与CNN</h1><h2 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h2><h3 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h3><p>采用滑动窗口的目标检测算法思路非常简单，它将检测问题转化为了图像分类问题。其基本原理就是采用不同大小和比例（宽高比）的窗口在整张图片上以一定的步长进行滑动，然后对这些窗口对应的区域做图像分类，这样就可以实现对整张图片的检测了</p><h3 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h3><p>但是这个方法有致命的缺点，就是你并不知道要检测的目标大小是什么规模，所以你要设置不同大小和比例的窗口去滑动，而且还要选取合适的步长。这样会产生很多的子区域，并且都要经过分类器去做预测，这需要很大的计算量，所以你的分类器不能太复杂，因为要保证速度。</p><h2 id="CNN"><a href="#CNN" class="headerlink" title="CNN"></a>CNN</h2><p>可以使用CNN实现更高效的滑动窗口方法</p><p>一种全卷积的方法，简单来说就是网络中用卷积层代替了全连接层</p><p>输入图片大小是16x16，经过一系列卷积操作，提取了2x2的特征图，但是这个2x2的图上每个元素都是和原图是一一对应的，这不就是相当于在原图上做大小为14x14的窗口滑动，且步长为2，共产生4个子区域。</p><p>之所CNN可以实现这样的效果是因为卷积操作的特性，就是图片的空间位置信息的不变性，尽管卷积过程中图片大小减少，但是位置对应关系还是保存的。</p><h3 id="缺点-1"><a href="#缺点-1" class="headerlink" title="缺点"></a>缺点</h3><p>尽管可以减少滑动窗口的计算量，但是只是针对一个固定大小与步长的窗口</p><h1 id="yolo如何做的"><a href="#yolo如何做的" class="headerlink" title="yolo如何做的"></a>yolo如何做的</h1><h4 id="思想"><a href="#思想" class="headerlink" title="思想"></a>思想</h4><p>直接将原始图片分割成互不重合的小方块，然后通过卷积最后生产这样大小的特征图。可以认为特征图的每个元素也是对应原始图片的一个小方块，然后用每个元素来可以预测那些中心点在该小方格内的目标。</p><h4 id="具体点的"><a href="#具体点的" class="headerlink" title="具体点的"></a>具体点的</h4><p>具体来说，Yolo的CNN网络将输入的图片分割成S*S个单元格，然后每个单元格负责去检测那些中心点落在该格子内的目标</p><p>每个单元格会预测 B个边界框（bounding box）以及边界框的置信度（confidence score)</p><h5 id="置信度"><a href="#置信度" class="headerlink" title="置信度"></a>置信度</h5><p>所谓置信度其实包含两个方面，一是这个边界框含有目标的可能性大小，二是这个边界框的准确度。</p><h5 id="含有目标的可能性大小"><a href="#含有目标的可能性大小" class="headerlink" title="含有目标的可能性大小"></a>含有目标的可能性大小</h5><p>记为 <img src="https://www.zhihu.com/equation?tex=Pr(object)" alt="[公式]"> ，当该边界框是背景时（即不包含目标），此时 <img src="https://www.zhihu.com/equation?tex=Pr(object)=0" alt="[公式]"> 。而当该边界框包含目标时， <img src="https://www.zhihu.com/equation?tex=Pr(object)=1" alt="[公式]"> </p><h5 id="边界框的准确度"><a href="#边界框的准确度" class="headerlink" title="边界框的准确度"></a>边界框的准确度</h5><p>可以用预测框与实际框（ground truth）的IOU（intersection over union，交并比）来表征，记为 <img src="https://www.zhihu.com/equation?tex=%5Ctext%7BIOU%7D%5E%7Btruth%7D_%7Bpred%7D" alt="[公式]"> 。</p><h5 id="因此置信度可以定义为"><a href="#因此置信度可以定义为" class="headerlink" title="因此置信度可以定义为 "></a>因此置信度可以定义为 <img src="https://www.zhihu.com/equation?tex=Pr(object)*%5Ctext%7BIOU%7D%5E%7Btruth%7D_%7Bpred%7D" alt="[公式]"></h5><h2 id="输出解释"><a href="#输出解释" class="headerlink" title="输出解释"></a>输出解释</h2><p>边界框的大小与位置可以用4个值来表征： <img src="https://www.zhihu.com/equation?tex=(x,+y,w,h)" alt="[公式]"> ，其中 <img src="https://www.zhihu.com/equation?tex=(x,y)" alt="[公式]"> 是边界框的中心坐标，而 <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=h" alt="[公式]"> 是边界框的宽与高</p><p>还有一点要注意，中心坐标的预测值 <img src="https://www.zhihu.com/equation?tex=(x,y)" alt="[公式]"> 是相对于每个单元格左上角坐标点的偏移值，并且单位是相对于单元格大小的，单元格的坐标定义如图6所示。而边界框的 <img src="https://www.zhihu.com/equation?tex=w" alt="[公式]"> 和 <img src="https://www.zhihu.com/equation?tex=h" alt="[公式]"> 预测值是相对于整个图片的宽与高的比例，这样4个元素的大小应该在 <img src="https://www.zhihu.com/equation?tex=%5B0,1%5D" alt="[公式]"> 范围。</p><h3 id="总输出"><a href="#总输出" class="headerlink" title="总输出"></a>总输出</h3><h4 id="一部分"><a href="#一部分" class="headerlink" title="一部分"></a>一部分</h4><p>每个边界框的预测值实际上包含5个元素： <img src="https://www.zhihu.com/equation?tex=(x,y,w,h,c)" alt="[公式]"> ，其中前4个表征边界框的大小与位置，而最后一个值是置信度。</p><h4 id="另一部分（分类问题）"><a href="#另一部分（分类问题）" class="headerlink" title="另一部分（分类问题）"></a>另一部分（分类问题）</h4><p>每一个单元格其还要给出预测出 <img src="https://www.zhihu.com/equation?tex=C" alt="[公式]"> 个类别概率值，但yolo1每个单元格只预测一个类别。后来的版本会有改进，暂时不提。</p><h4 id="所以"><a href="#所以" class="headerlink" title="所以"></a>所以</h4><p>一个单元格会有<img src="https://www.zhihu.com/equation?tex=(B*5+C)" alt="[公式]">个值</p><p>总的S*S个会有 <img src="https://www.zhihu.com/equation?tex=S%5Ctimes+S%5Ctimes+(B*5+C)" alt="[公式]">个值</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;只说结论&quot;&gt;&lt;a href=&quot;#只说结论&quot; class=&quot;headerlink&quot; title=&quot;只说结论&quot;&gt;&lt;/a&gt;只说结论&lt;/h1&gt;&lt;p&gt;yolo1 将一张图片分割为S*S个单元格，每个单元格输出&lt;strong&gt;（Bx5+C）&lt;/strong&gt;个值。&lt;/p&gt;
&lt;</summary>
      
    
    
    
    <category term="Yolo学习" scheme="http://example.com/categories/Yolo%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>yolov1 具体网络结构</title>
    <link href="http://example.com/wiki/Yolo%E5%AD%A6%E4%B9%A0/yolo1%20%E5%85%B7%E4%BD%93%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/"/>
    <id>http://example.com/wiki/Yolo%E5%AD%A6%E4%B9%A0/yolo1%20%E5%85%B7%E4%BD%93%E7%BD%91%E7%BB%9C%E7%BB%93%E6%9E%84/</id>
    <published>2025-08-12T08:34:27.000Z</published>
    <updated>2025-08-24T18:53:10.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="大体结构"><a href="#大体结构" class="headerlink" title="大体结构"></a>大体结构</h1><p>Yolo采用卷积网络来提取特征，然后使用全连接层来得到预测值。</p><p><strong>卷积层：</strong>主要使用1x1卷积来做channle reduction，然后紧跟3x3卷积。</p><p>卷积层和全连接层，采用Leaky ReLU激活函数： <img src="https://www.zhihu.com/equation?tex=max(x,+0.1x)" alt="[公式]"> </p><p>但是最后一层却采用线性激活函数。</p><h2 id="直接上图"><a href="#直接上图" class="headerlink" title="直接上图"></a>直接上图</h2><p><img src="https://pic4.zhimg.com/80/v2-5d099287b1237fa975b1c19bacdfc07f_720w.jpg" alt="img"></p><p>这里我没看懂最后一个为什么从一条又变成了一块。</p><h2 id="输出的具体解释"><a href="#输出的具体解释" class="headerlink" title="输出的具体解释"></a>输出的具体解释</h2><p><img src="https://pic1.zhimg.com/v2-8630f8d3dbe3634f124eaf82f222ca94_r.jpg" alt="preview"></p><h1 id="关于训练"><a href="#关于训练" class="headerlink" title="关于训练"></a>关于训练</h1><p>Yolo算法将目标检测看成回归问题，所以采用的是均方差损失函数。</p><h2 id="权重部分"><a href="#权重部分" class="headerlink" title="权重部分"></a>权重部分</h2><p>对不同的部分采用了不同的权重值。</p><p>首先区分定位误差和分类误差。</p><h4 id="定位误差"><a href="#定位误差" class="headerlink" title="定位误差"></a>定位误差</h4><p>即边界框坐标预测误差，采用较大的权重 <img src="https://www.zhihu.com/equation?tex=%5Clambda+_%7Bcoord%7D=5" alt="[公式]"> 。</p><h4 id="分类误差"><a href="#分类误差" class="headerlink" title="分类误差"></a>分类误差</h4><p>然后其区分不包含目标的边界框与含有目标的边界框的置信度，对于前者，采用较小的权重值 <img src="https://www.zhihu.com/equation?tex=%5Clambda+_%7Bnoobj%7D=0.5" alt="[公式]"> ，其它权重值均设为1。</p><h2 id="误差部分"><a href="#误差部分" class="headerlink" title="误差部分"></a>误差部分</h2><p>采用均方误差，其同等对待大小不同的边界框，</p><p>但是实际上较小的边界框的坐标误差应该要比较大的边界框要更敏感。为了保证这一点，将网络的边界框的宽与高预测改为对其平方根的预测，即预测值变为 <img src="https://www.zhihu.com/equation?tex=(x,y,%5Csqrt%7Bw%7D,+%5Csqrt%7Bh%7D)" alt="[公式]"> 。</p><h2 id="另外"><a href="#另外" class="headerlink" title="另外"></a>另外</h2><p>由于每个单元格预测多个边界框。但是其对应类别只有一个。那么在训练时，如果该单元格内确实存在目标，那么只选择与ground truth的IOU最大的那个边界框来负责预测该目标，而其它边界框认为不存在目标。</p><h4 id="好处"><a href="#好处" class="headerlink" title="好处"></a>好处</h4><p>这样设置的一个结果将会使一个单元格对应的边界框更加专业化，其可以分别适用不同大小，不同高宽比的目标，从而提升模型性能。</p><h4 id="缺点"><a href="#缺点" class="headerlink" title="缺点"></a>缺点</h4><p>如果一个单元格内存在多个目标怎么办，其实这时候Yolo算法就只能选择其中一个来训练</p><p><strong>注意：</strong>对于不存在对应目标的边界框，其误差项就是只有置信度，坐标项误差是没法计算的。而只有当一个单元格内确实存在目标时，才计算分类误差项，否则该项也是无法计算的。</p><h3 id="最终的损失函数计算如下："><a href="#最终的损失函数计算如下：" class="headerlink" title="最终的损失函数计算如下："></a>最终的损失函数计算如下：</h3><p><img src="https://pic3.zhimg.com/80/v2-45795a63cdbaac8c05d875dfb6fcfb5a_720w.jpg" alt="img"></p><h1 id="关于预测"><a href="#关于预测" class="headerlink" title="关于预测"></a>关于预测</h1><p>这里我们不考虑batch，认为只是预测一张输入图片。根据前面的分析，最终的网络输出是 <img src="https://www.zhihu.com/equation?tex=7%5Ctimes+7+%5Ctimes+30" alt="[公式]"> ，但是我们可以将其分割成三个部分</p><p>类别概率部分为 <img src="https://www.zhihu.com/equation?tex=%5B7,+7,+20%5D" alt="[公式]"> </p><p>置信度部分为 <img src="https://www.zhihu.com/equation?tex=%5B7,7,2%5D" alt="[公式]"> </p><p>置信度部分为 <img src="https://www.zhihu.com/equation?tex=%5B7,7,2%5D" alt="[公式]"> </p><p>然后将前两项相乘可以得到类别置信度值为 <img src="https://www.zhihu.com/equation?tex=%5B7,+7,2,20%5D" alt="[公式]"></p><p>这里总共预测了 <img src="https://www.zhihu.com/equation?tex=7*7*2=98" alt="[公式]"> 个边界框。</p><h2 id="有两种处理方法"><a href="#有两种处理方法" class="headerlink" title="有两种处理方法"></a>有两种处理方法</h2><h4 id="第一种策略"><a href="#第一种策略" class="headerlink" title="第一种策略"></a>第一种策略</h4><p>首先，对于<strong>每个预测框</strong>根据类别置信度选取<strong>置信度最大</strong>的那个类别作为其预测标签</p><p>经过这层处理我们得到各个预测框的预测类别及对应的置信度值，其大小都是 <img src="https://www.zhihu.com/equation?tex=%5B7,7,2%5D" alt="[公式]"> 。</p><p>一般情况下，会<strong>设置置信度阈值</strong>，就是<strong>将置信度小于该阈值的box过滤掉</strong>，所以经过这层处理，<strong>剩余</strong>的是<strong>置信度比较高</strong>的预测框。</p><p>最后再对这些预测框使用<strong>NMS算法</strong>。</p><h4 id="第二种策略"><a href="#第二种策略" class="headerlink" title="第二种策略"></a>第二种策略</h4><p>先使用NMS，然后再确定各个box的类别，</p><p>对于98个boxes，首先将小于置信度阈值的值归0，然后分类别地对置信度值采用NMS，这里NMS处理结果不是剔除，而是将其置信度值归为0。最后才是确定各个box的类别，当其置信度值不为0时才做出检测结果输出。</p><p><strong>我读到的文章说：</strong>这个策略不是很直接，但是貌似Yolo源码就是这样做的。Yolo论文里面说NMS算法对Yolo的性能是影响很大的，所以可能这种策略对Yolo更好。但是我测试了普通的图片检测，两种策略结果是一样的。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;大体结构&quot;&gt;&lt;a href=&quot;#大体结构&quot; class=&quot;headerlink&quot; title=&quot;大体结构&quot;&gt;&lt;/a&gt;大体结构&lt;/h1&gt;&lt;p&gt;Yolo采用卷积网络来提取特征，然后使用全连接层来得到预测值。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;卷积层：&lt;/strong&gt;主要</summary>
      
    
    
    
    <category term="Yolo学习" scheme="http://example.com/categories/Yolo%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
  <entry>
    <title>anchor box（先验框）</title>
    <link href="http://example.com/wiki/Yolo%E5%AD%A6%E4%B9%A0/anchor%20boxes/"/>
    <id>http://example.com/wiki/Yolo%E5%AD%A6%E4%B9%A0/anchor%20boxes/</id>
    <published>2025-08-10T08:34:27.000Z</published>
    <updated>2025-08-24T18:32:30.000Z</updated>
    
    <content type="html"><![CDATA[<h1 id="anchor-box（先验框）"><a href="#anchor-box（先验框）" class="headerlink" title="anchor box（先验框）"></a>anchor box（先验框）</h1><p>anchor （锚; 给以安全感的人(或物); 精神支柱; 顶梁柱;）</p><h2 id="为什么"><a href="#为什么" class="headerlink" title="为什么"></a>为什么</h2><p>对象检测中存在一个问题就是每个格子只能预测一个对象，如果想让一个格子检测出多个对象，用anchor box</p><h2 id="以前的做法"><a href="#以前的做法" class="headerlink" title="以前的做法"></a>以前的做法</h2><p>假设我们有这样一张图片，对于这个例子，我们使用3x3的网格，可以观察到，行人和汽车的中心几乎在同一个网格，然而我们以前的方法一个格子只能预测一个对象，而且对于y输出的的向量量𝑦 &#x3D; [𝑝𝑐 𝑏𝑥 𝑏𝑦 𝑏ℎ 𝑏𝑤 𝑐1 𝑐2 𝑐3 ]，你可以检测这三个类别，行人、汽车和摩托车，它将无法输出检测结果，所以我必须从两个检测结果中选一个，这便影响了模型性能，导致一些对象被丢弃无法检测出来。<br><img src="https://img-blog.csdnimg.cn/20200208232504699.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDYyMzYzNw==,size_16,color_FFFFFF,t_70" alt="img"></p><h2 id="anchor-box-引入"><a href="#anchor-box-引入" class="headerlink" title="anchor box 引入"></a>anchor box 引入</h2><p><img src="https://img-blog.csdnimg.cn/2020020823275943.png" alt="img"></p><p>预先定义两个不同形状的 anchor box，或者 anchor box 形状</p><p>一般来说，可能会用更多的 anchor box，可能要 5 个甚至更多，为介绍方便就用两个 anchor box</p><p>定义类别标签，用的向量不再是下面这个：<br>[𝑝𝑐 𝑏𝑥 𝑏𝑦 𝑏ℎ 𝑏𝑤 𝑐1 𝑐2 𝑐3]𝑇</p><p>而是输出重复两次：</p><p>𝑦 &#x3D; [𝑝𝑐 𝑏𝑥 𝑏𝑦 𝑏ℎ 𝑏𝑤 𝑐1 𝑐2 𝑐3 𝑝𝑐 𝑏𝑥 𝑏𝑦 𝑏ℎ 𝑏𝑤 𝑐1 𝑐2 𝑐3]𝑇</p><p>前一半是box1后一半是box2</p><p>行人一般符合anchor box1形状，所以用anchor box1来预测行人会达到很好的效果，这么编码𝑝𝑐 &#x3D; 1，代表有个行人，用𝑏𝑥,𝑏𝑦,𝑏ℎ和𝑏𝑤来编码包住行人的边界框，然后用𝑐1,𝑐2,𝑐3(𝑐1 &#x3D; 1,𝑐2 &#x3D; 0,𝑐3 &#x3D; 0)来说明这个对象是个行人。<br>汽车一般是box2，方式同理</p><p><strong>文章没说编码完一部分后剩下的怎么处理</strong></p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>所以，总的来说，anchor box是这么来做的，现在每个对象和以前一样根据中心点分配到一个格子中，然后看和每个anchor box的IoU（交并比），选择IoU最高的那个，用这个anchor box来进行预测。输出y的维度是<strong>n</strong>x<strong>n</strong>x<strong>m</strong>x<strong>c</strong>（<strong>n</strong>为图片分成<strong>n</strong>x<strong>n</strong>份，<strong>m</strong>为anchor box数量，<strong>c</strong>为class类别数）</p><h2 id="不足"><a href="#不足" class="headerlink" title="不足"></a>不足</h2><p>1.两个 anchor box，但在同一个格子中有三个对象，这种情况算法处理不好，你希望这种情况不会发生，但如果真的发生了，这个算法并没有很好的处理办法</p><p>2.两个对象都分配到一个格子中，而且它们的 anchor box 形状也一样，也不好办</p><p><strong>看文章说其实这两种情况很少出现</strong>，特别是如果你用的是 19×19 网格而不是3×3 的网格</p><h2 id="怎么选box？"><a href="#怎么选box？" class="headerlink" title="怎么选box？"></a>怎么选box？</h2><p>1.一般手工指定anchor box形状，根据要检测的对象，指定有针对性地anchor box，可选择5-10个anchor box，使其尽可能覆盖到不同形状。<br>2.使用K-means聚类算法获得anchor box。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;anchor-box（先验框）&quot;&gt;&lt;a href=&quot;#anchor-box（先验框）&quot; class=&quot;headerlink&quot; title=&quot;anchor box（先验框）&quot;&gt;&lt;/a&gt;anchor box（先验框）&lt;/h1&gt;&lt;p&gt;anchor （锚; 给以安全感的人</summary>
      
    
    
    
    <category term="Yolo学习" scheme="http://example.com/categories/Yolo%E5%AD%A6%E4%B9%A0/"/>
    
    
  </entry>
  
</feed>
